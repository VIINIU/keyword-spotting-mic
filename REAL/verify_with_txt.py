import numpy as np
import torch
import torch.nn as nn
import snntorch as snn
from snntorch import surrogate
import os 

# ====================================================
# 1. [ì‹ ê·œ] Verilogì˜ ì •ìˆ˜ ì—°ì‚°ì„ ìœ„í•œ í—¬í¼ í•¨ìˆ˜
# ====================================================

def quantize_to_int(tensor: torch.Tensor, m: int, n: int) -> torch.Tensor:
    """
    Float í…ì„œë¥¼ Qm.n 'ì •ìˆ˜' í…ì„œë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    Scale(2^n)ë§Œ í•˜ê³  Unscale(ë‚˜ëˆ„ê¸°)ì„ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    """
    scale_factor = 2**n
    INT16_MIN = -32768
    INT16_MAX = 32767
    quantized_tensor = torch.round(tensor * scale_factor)
    quantized_tensor = torch.clamp(
        quantized_tensor, 
        min=INT16_MIN, 
        max=INT16_MAX
    )
    return quantized_tensor.long() 

# ğŸš¨ [ì‹ ê·œ] tb_snn_core.vì˜ $readmemhë¥¼ ëª¨ë°©í•˜ëŠ” .txt ë¡œë”
def read_spike_stimulus_txt(txt_file_path: str, n_mels: int) -> np.ndarray:
    """
    Verilogì˜ 16ì§„ìˆ˜ ìŠ¤íŒŒì´í¬ .txt íŒŒì¼ì„ ì½ì–´
    (T, N_MELS) í˜•íƒœì˜ float32 numpy ë°°ì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    spike_vectors = []
    
    with open(txt_file_path, 'r') as f:
        lines = f.readlines()
        
    for line in lines:
        hex_str = line.strip()
        if not hex_str:
            continue
            
        # 1. 16ì§„ìˆ˜ -> 20ë¹„íŠ¸ 2ì§„ìˆ˜ ë¬¸ìì—´
        bin_str = f'{int(hex_str, 16):0{n_mels}b}'
        
        # 2. 2ì§„ìˆ˜ ë¬¸ìì—´ -> float ë¦¬ìŠ¤íŠ¸
        # (Verilog [19:0] ìˆœì„œì— ë§ê²Œ reversed)
        # (ëª¨ë¸ ì…ë ¥ì€ 0.0 ë˜ëŠ” 1.0 floatì—¬ì•¼ í•¨)
        spike_vector = [float(bit) for bit in reversed(bin_str)]
        spike_vectors.append(spike_vector)
        
    # (T, N_MELS) í˜•íƒœì˜ numpy ë°°ì—´ë¡œ ë°˜í™˜
    return np.array(spike_vectors, dtype=np.float32)

# ====================================================
# 2. SNN ëª¨ë¸ (Verilog í•˜ë“œì›¨ì–´ ëª¨ë°©)
# ====================================================
class WWS_SNN_Hardware_Sim(nn.Module):
    # --- Verilogì™€ 100% ë™ì¼í•œ íŒŒë¼ë¯¸í„° ---
    QW_M, QW_N = 7, 9  # ê°€ì¤‘ì¹˜/í¸í–¥ Q-Format (Q7.9)
    QT_M, QT_N = 5, 11 # ì„ê³„ê°’ Q-Format (Q5.11)
    
    VERILOG_BETA_INT = 62259
    VERILOG_BETA_FLOAT = 62259 / 65536.0 # 0.950002...
    VERILOG_THRESH_INT_Q5_11 = 1024       # 16'h0400
    
    # Verilogì˜ Q-Formatì— ë§ì¶˜ ì‹¤ìˆ˜ ì„ê³„ê°’ (ë²„ê·¸ ìˆ˜ì •ëœ >> ë¡œì§)
    VERILOG_THRESH_FLOAT_ALIGNED = (VERILOG_THRESH_INT_Q5_11 >> (QT_N - QW_N)) / (2**QW_N) # 0.5

    def __init__(self, num_inputs, num_hiddens_1, num_hiddens_2, num_outputs, spike_grad):
        super().__init__()
        
        # 1. [ìˆ˜ì •] Verilogì˜ ìˆ˜í•™ì„ ì‚¬ìš©í•˜ë„ë¡ BETA, THRESHOLD ê³ ì •
        self.lif1 = snn.Leaky(beta=self.VERILOG_BETA_FLOAT, 
                              threshold=self.VERILOG_THRESH_FLOAT_ALIGNED, 
                              spike_grad=spike_grad, reset_mechanism="subtract")
        
        self.lif2 = snn.Leaky(beta=self.VERILOG_BETA_FLOAT, 
                              threshold=self.VERILOG_THRESH_FLOAT_ALIGNED, 
                              spike_grad=spike_grad, reset_mechanism="subtract")
        
        self.lif3 = snn.Leaky(beta=self.VERILOG_BETA_FLOAT, 
                              threshold=self.VERILOG_THRESH_FLOAT_ALIGNED, 
                              spike_grad=spike_grad, reset_mechanism="subtract")
        
        self.W1_int = None
        self.B1_int = None
        self.W2_int = None
        self.B2_int = None
        self.W3_int = None
        self.B3_int = None

        self.init_state()

    def init_state(self):
        self.mem1 = self.lif1.init_leaky()
        self.mem2 = self.lif2.init_leaky()
        self.mem3 = self.lif3.init_leaky()

    def load_weights_from_pth(self, state_dict, device):
        """
        .pth íŒŒì¼(float)ì„ ë¡œë“œí•œ ë’¤, Verilogê°€ ì‚¬ìš©í•  'ì •ìˆ˜' ê°€ì¤‘ì¹˜ë¡œ ë³€í™˜
        """
        self.W1_int = quantize_to_int(state_dict['fc1.weight'], self.QW_M, self.QW_N).to(device)
        self.B1_int = quantize_to_int(state_dict['fc1.bias'], self.QW_M, self.QW_N).to(device)
        self.W2_int = quantize_to_int(state_dict['fc2.weight'], self.QW_M, self.QW_N).to(device)
        self.B2_int = quantize_to_int(state_dict['fc2.bias'], self.QW_M, self.QW_N).to(device)
        self.W3_int = quantize_to_int(state_dict['fc3.weight'], self.QW_M, self.QW_N).to(device)
        self.B3_int = quantize_to_int(state_dict['fc3.bias'], self.QW_M, self.QW_N).to(device)
        print("âœ… Python ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ Verilogì˜ 'ì •ìˆ˜' í¬ë§·ìœ¼ë¡œ ë³€í™˜ ì™„ë£Œ.")

    # ğŸš¨ [í•µì‹¬ ìˆ˜ì •] F.linear()ë¥¼ Verilogì˜ 'ì •ìˆ˜ ë§ì…ˆ'ìœ¼ë¡œ ëŒ€ì²´
    def hardware_true_forward(self, x, mem1, mem2, mem3):
        
        x_int = x.long().unsqueeze(-1) 
        
        # --- 1. L1 (MAC + LIF) ---
        cur1_int = torch.bmm(self.W1_int.unsqueeze(0).repeat(x.size(0), 1, 1), x_int)
        cur1_int = cur1_int.squeeze(-1) + self.B1_int 
        
        # [ë””ë²„ê¹…] T=0ì¼ ë•Œ j=0 ê°’ í™•ì¸
        if T_STEP_COUNTER == 0:
             print("\n--- ğŸ [PYTHON T=0] Layer 1 (í•˜ë“œì›¨ì–´ ëª¨ë°©) ---")
             print(f"  > Python L1, j=0 cur_in (int): {cur1_int[0, 0].item() & 0xFFFFFFFF :08x}")
             print("--------------------------------------------------\n")

        cur1_float = cur1_int.float() / (2**self.QW_N)
        spk1, mem1 = self.lif1(cur1_float, mem1)
        
        # --- 2. L2 (MAC + LIF) ---
        spk1_int = spk1.long().unsqueeze(-1) # [B, 128, 1]
        cur2_int = torch.bmm(self.W2_int.unsqueeze(0).repeat(x.size(0), 1, 1), spk1_int)
        cur2_int = cur2_int.squeeze(-1) + self.B2_int
        cur2_float = cur2_int.float() / (2**self.QW_N)
        spk2, mem2 = self.lif2(cur2_float, mem2)
        
        # --- 3. L3 (MAC + LIF) ---
        spk2_int = spk2.long().unsqueeze(-1) # [B, 128, 1]
        cur3_int = torch.bmm(self.W3_int.unsqueeze(0).repeat(x.size(0), 1, 1), spk2_int)
        cur3_int = cur3_int.squeeze(-1) + self.B3_int
        cur3_float = cur3_int.float() / (2**self.QW_N)
        spk3, mem3 = self.lif3(cur3_float, mem3)
        
        return spk3, mem1, mem2, mem3

# ====================================================
# 3. ê²€ì¦ ì„¤ì • (ğŸš¨ .txt íŒŒì¼ë¡œ ë³€ê²½)
# ====================================================
# VERIFY_NPY_FILE = "C:/.../spike_input_16bit_1.npy"
VERIFY_TXT_FILE = "C:/vini_dir/kws_mic/spike_stimulus_GOOD_3_neg.txt" # ğŸš¨ tb_snn_core.v ê²½ë¡œì™€ ì¼ì¹˜
QAT_MODEL_PATH = "./wws_snn_qat_final_weights.pth" 

N_MELS = 20 
NUM_HIDDENS_1 = 128
NUM_HIDDENS_2 = 128
NUM_OUTPUTS = 2
spike_grad = surrogate.atan()
T_MAX = 3000

T_STEP_COUNTER = 0 # ğŸš¨ ë””ë²„ê¹…ìš© ê¸€ë¡œë²Œ ì¹´ìš´í„°

# ====================================================
# 4. ë©”ì¸ ê²€ì¦ ë¡œì§ (ğŸš¨ .txt íŒŒì¼ ë¡œë”ë¡œ ë³€ê²½)
# ====================================================
if __name__ == "__main__":
    
    device = torch.device("cpu")
    print(f"ê²€ì¦ ì‹œì‘: {VERIFY_TXT_FILE} (ëª¨ë¸: {QAT_MODEL_PATH})")

    # 1. ëª¨ë¸ ìƒì„±
    net = WWS_SNN_Hardware_Sim(N_MELS, NUM_HIDDENS_1, NUM_HIDDENS_2, NUM_OUTPUTS, spike_grad).to(device)
    
    try:
        # 2. .pth (float) ë¡œë“œ -> Verilog 'ì •ìˆ˜' ê°€ì¤‘ì¹˜ë¡œ ë³€í™˜
        state_dict = torch.load(QAT_MODEL_PATH, map_location=device)
        net.load_weights_from_pth(state_dict, device)
        
    except Exception as e:
        print(f"ğŸš¨ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        exit()
    
    net.eval() # (ì¶”ë¡  ëª¨ë“œ)

    # 3. ğŸš¨ [ìˆ˜ì •] NPY ë¡œë” ëŒ€ì‹  TXT ë¡œë” ì‚¬ìš©
    try:
        spike_data_np = read_spike_stimulus_txt(VERIFY_TXT_FILE, N_MELS)
        print(f"âœ… TXT íŒŒì¼ ë¡œë“œ ì„±ê³µ. ì´ {spike_data_np.shape[0]} íƒ€ì„ìŠ¤í….")
    except Exception as e:
        print(f"ğŸš¨ TXT íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        exit()

    # (íŒ¨ë”©/ì ˆì‚­ ë¡œì§ - ì›ë³¸ ìŠ¤í¬ë¦½íŠ¸ì™€ ë™ì¼)
    if spike_data_np.shape[0] > T_MAX:
         spike_data_np = spike_data_np[:T_MAX, :]
    elif spike_data_np.shape[0] < T_MAX:
         padding = np.zeros((T_MAX - spike_data_np.shape[0], N_MELS), dtype=np.float32)
         spike_data_np = np.vstack([spike_data_np, padding])
         
    data_tensor = torch.as_tensor(spike_data_np, dtype=torch.float32).to(device)
    data_tensor = data_tensor.unsqueeze(0) # (T, N_MELS) -> (Batch=1, T, N_MELS)
    
    # [ì…ë ¥ ê²€ì¦ í”Œë˜ê·¸]
    first_spike_vector_np = spike_data_np[0, :]
    # (float 1.0/0.0 -> int 1/0 ë³€í™˜)
    bin_str = "".join(['1' if x > 0 else '0' for x in first_spike_vector_np])
    hex_str = f'{int(bin_str, 2):05X}'
    print(f"--- ğŸ [PYTHON T=0] Input Spike Vector (from TXT): {hex_str} ---")

    # 4. SNN ì¶”ë¡  (T_MAX ìŠ¤í…)
    net.init_state()
    total_output_spikes = torch.zeros(1, NUM_OUTPUTS).to(device)
    
    with torch.no_grad():
        for step in range(T_MAX):
            T_STEP_COUNTER = step # ğŸš¨ ë””ë²„ê¹… ì¹´ìš´í„° ì—…ë°ì´íŠ¸
            
            spk_out, net.mem1, net.mem2, net.mem3 = net.hardware_true_forward(
                data_tensor[:, step, :], net.mem1, net.mem2, net.mem3
            )
            total_output_spikes += spk_out

    # 5. ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print("\n================= ğŸ 'ì§„ì§œ' íŒŒì´ì¬ ì •ë‹µì§€ (í•˜ë“œì›¨ì–´ ëª¨ë°©) ==================")
    print(f"  {VERIFY_TXT_FILE} íŒŒì¼ì„ ì‚¬ìš©í•œ ê²°ê³¼:")
    print(f"  ìµœì¢… ëˆ„ì  ìŠ¤íŒŒì´í¬ (0: neg, 1: alexa):")
    print(f"   >> {total_output_spikes[0].cpu().numpy()}")
    print("=======================================================================")